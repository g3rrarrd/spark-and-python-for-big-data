{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48d38d60-acda-436b-beb0-6a5be1c1bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/gerardo-rodriguez/spark-4.0.0-bin-hadoop3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e33adf-d0b7-47e2-bdd4-ea4057ba748f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/08/27 11:38:58 WARN Utils: Your hostname, Lanz-Lenovo, resolves to a loopback address: 127.0.1.1; using 192.168.1.145 instead (on interface wlp2s0)\n",
      "25/08/27 11:38:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/27 11:38:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/08/27 11:39:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/08/27 11:39:00 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/08/27 11:39:00 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('ALS').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17bd873b-11ce-420b-bc07-eee9150e3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34bd9bb1-ce16-4f90-9c5d-d863503ec445",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('user_id', LongType(), True),\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('age', IntegerType(), True),\n",
    "    StructField('country', StringType(), True),\n",
    "    StructField('film_id', StringType(), True),\n",
    "    StructField('title', StringType(), True),\n",
    "    StructField('genre', StringType(), True),\n",
    "    StructField('duration', StringType(), True),\n",
    "    StructField('rating', DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193ec475-24e2-4c7b-8da9-878f39528020",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('../ratings_netlfix/', schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7b841c9-930e-43e2-ac50-a6e4d89d28a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- film_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e1c55b3-0491-4052-a5f2-f6fa7e1da1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, round, regexp_replace, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce59b1d-49f3-44fe-95c0-a71630543498",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('rating', round('rating'))\n",
    "df = df.withColumn('film_id', regexp_replace(col('film_id'), 's', '').cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0179255c-7459-4e28-9712-4f7f4c398839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- film_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433c43b-4d6f-449b-989a-57820c0aa4ac",
   "metadata": {},
   "source": [
    "### Create ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7374895c-f332-4a3d-9953-450fd6f0db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4f36af6-44b7-47b0-8835-6b64657c5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78a79a4e-7aeb-44cd-8844-6564a409861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(userCol='user_id', itemCol='film_id', ratingCol='rating',seed=1, coldStartStrategy='drop', implicitPrefs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6152460-c98b-4cae-b55b-f4b348728818",
   "metadata": {},
   "source": [
    "## Option 1 for find the best value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68ef5b67-42ed-413e-a69f-42684cf01edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_params():\n",
    "    reg_params = np.arange(0.01, 0.2, 0.01)\n",
    "    results = {}\n",
    "    \n",
    "    for reg_param in reg_params:\n",
    "        als.setRegParam(reg_param)\n",
    "        model = als.fit(train_data)\n",
    "        predictions = model.transform(test_data)\n",
    "        \n",
    "        rmse_evaluator = RegressionEvaluator(labelCol='rating', predictionCol='prediction', metricName='rmse')\n",
    "        mae_evaluator = RegressionEvaluator(labelCol='rating', predictionCol='prediction', metricName='mae')\n",
    "        \n",
    "        rmse = rmse_evaluator.evaluate(predictions)\n",
    "        mae = mae_evaluator.evaluate(predictions)\n",
    "        \n",
    "        results[reg_param] = {'rmse': rmse, 'mae': mae}\n",
    "    \n",
    "    best_reg_param = min(results, key=lambda x: results[x]['rmse'])\n",
    "    best_rmse = results[best_reg_param]['rmse']\n",
    "    \n",
    "    print(f'Best reg_param: {best_reg_param} with RMSE: {best_rmse:.4f}')\n",
    "    \n",
    "    return best_reg_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53060b0b-6cdb-4e39-b1b3-d46956d12a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_rank_params():\n",
    "    rank_array = [x for x in range(10, 40, 10)]\n",
    "    \n",
    "    rank_dict = {}\n",
    "    \n",
    "    for rank in rank_array:\n",
    "        als.setRank(rank)\n",
    "        model = als.fit(train_data)\n",
    "        pred = model.transform(test_data)\n",
    "        \n",
    "        evaluator = RegressionEvaluator(labelCol='rating', predictionCol='prediction')\n",
    "        rmse = evaluator.evaluate(pred)\n",
    "        \n",
    "        rank_dict[rank] = rmse\n",
    "    \n",
    "    best_rank = min(rank_dict, key=rank_dict.get)\n",
    "    best_rmse = rank_dict[best_rank]\n",
    "    \n",
    "    print(f'Best rank: {best_rank} with RMSE: {best_rmse:.4f}')\n",
    "    \n",
    "    return best_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed417ab4-8de0-4d8c-975e-a5b2b88dffe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best reg_param: 0.1 with RMSE: 2.9162\n"
     ]
    }
   ],
   "source": [
    "reg_param = best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ea20cc0-bf39-4bd0-982c-19fde0a2bf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best rank: 20 with RMSE: 2.9167\n"
     ]
    }
   ],
   "source": [
    "rank = best_rank_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4a003a-38d1-4176-b9cb-d807364d5c4f",
   "metadata": {},
   "source": [
    "## option 2 for find the best value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b7804-e414-454b-830f-37b1e3d7ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d52f7e-be6a-4f0f-93aa-a12a654f4783",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(als.rank, [10, 20, 30]) \\\n",
    "    .addGrid(als.regParam, [0.01, 0.05, 0.1]) \\\n",
    "    .addGrid(als.maxIter, [10, 20]) \\\n",
    "    .build()\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3\n",
    ")\n",
    "\n",
    "model_cv = cv.fit(train_data)\n",
    "best_model = model_cv.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d902b8e-1ca1-4b13-8222-9108261165dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Best rank:\", best_model.rank)\n",
    "print(\"Best regParam:\", best_model._java_obj.parent().getRegParam())\n",
    "print(\"Best maxIter:\", best_model._java_obj.parent().getMaxIter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e006e574-9b25-460f-b0c0-6f3f3eaf4612",
   "metadata": {},
   "outputs": [],
   "source": [
    "als = als.setRegParam(reg_param).setRank(rank).setMaxIter(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "882cb2b6-a15d-42a8-8c04-0e1bd6627adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "318b22ae-0ad0-4116-bb33-e775ae924f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|rating|prediction|\n",
      "+------+----------+\n",
      "|   5.0|0.47612974|\n",
      "|   2.0|0.37992322|\n",
      "|   2.0| 0.3169993|\n",
      "|   1.0|0.29991472|\n",
      "|   0.0|  0.219556|\n",
      "+------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(test_data)\n",
    "prediction.select('rating', 'prediction').orderBy(col('prediction').desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8797980e-0f45-4342-8393-da9877901e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.915936487658402"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = RegressionEvaluator(metricName='rmse', predictionCol='prediction', labelCol='rating')\n",
    "\n",
    "print('RMSE')\n",
    "eva.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb2376-1239-4f2b-a97b-ad6d579140a5",
   "metadata": {},
   "source": [
    "## Test For users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4db6065b-1fd8-47c8-83cd-0b6a5eed3d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+\n",
      "|user_id|film_id| prediction|\n",
      "+-------+-------+-----------+\n",
      "|    100|   1244|0.002501208|\n",
      "+-------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_data = test_data.filter(test_data['user_id'] == 100).select('user_id', 'film_id')\n",
    "prediction_user = model.transform(user_data)\n",
    "prediction_user.orderBy('prediction', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f97a4bb-067c-4274-a11a-d89807d1e3a4",
   "metadata": {},
   "source": [
    "## Justificación de resultados en ALS\n",
    "\n",
    "El modelo de recomendación basado en ALS (Alternating Least Squares) presentó métricas de predicción bajas (RMSE alto, R² bajo o negativo). Esto no se debe a un error en la implementación del algoritmo, sino a las características propias del dataset utilizado:\n",
    "\n",
    "Datos aleatorios:\n",
    "Las calificaciones fueron generadas de manera completamente aleatoria, sin patrones reales de preferencia entre usuarios y películas. ALS aprende a partir de correlaciones usuario–ítem, por lo que en ausencia de éstas, no puede generalizar adecuadamente.\n",
    "\n",
    "Escasez de interacciones:\n",
    "Algunos usuarios y películas poseen pocas interacciones, lo que genera mayor dispersión en la matriz de usuario–ítem y limita el aprendizaje del modelo.\n",
    "\n",
    "Dependencia de hiperparámetros:\n",
    "Aunque ALS permite mejorar el rendimiento mediante ajuste de parámetros como rank, regParam y maxIter, en este caso la naturaleza aleatoria de los datos impide obtener mejoras significativas.\n",
    "\n",
    "En conclusión, los valores bajos obtenidos reflejan la falta de relación lógica en los datos y no una deficiencia en el modelo. En un escenario real, con calificaciones de usuarios auténticos, se esperaría que ALS detecte patrones de consumo y logre un desempeño mucho más robusto.\n",
    "\n",
    "## Justification of ALS Results\n",
    "\n",
    "The recommendation model based on ALS (Alternating Least Squares) showed low prediction performance (high RMSE, low or even negative R²). This outcome is not due to an error in the algorithm implementation, but rather to the characteristics of the dataset used:\n",
    "\n",
    "Random data:\n",
    "The ratings were generated completely at random, with no real patterns of user–movie preferences. Since ALS learns from user–item correlations, the absence of such patterns prevents the model from generalizing effectively.\n",
    "\n",
    "Sparse interactions:\n",
    "Some users and movies have very few interactions, which increases the sparsity of the user–item matrix and limits the model’s learning capacity.\n",
    "\n",
    "Hyperparameter sensitivity:\n",
    "Although ALS performance can be improved through parameter tuning (rank, regParam, maxIter), in this case the random nature of the dataset prevents significant improvements.\n",
    "\n",
    "In conclusion, the low values obtained reflect the lack of logical relationships in the dataset, rather than a weakness in the model itself. In a real-world scenario with genuine user ratings, ALS would be expected to detect consumption patterns and achieve much more reliable performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f1570-a683-4616-a9ea-bd8c1d32c1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
